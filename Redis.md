# Redis

## 速度快的原因

### 基于内存实现

### 高效的数据结构

- String
  - 通过动态字符串实现
  - 并且二进制安全
- List
  - 双端链表
- Hash
  - 压缩链表
- Set
  - 字典
- Zset
  - 跳跃表

### 合适的数据编码

- 对越每一种数据类型来说，底层的支持可能是多种数据结构，什么时候使用哪种数据结构，这就涉及到了编码转化的问题。
- String
  - 存储数字的话，采用int类型的编码，如果是非数字的话，使用raw编码
- List
  - 字符串长度及元素个数小于一定范围使用ziplist编码，任一条件不满足，则转化为hashtable编码
- Hash
  - hash 对象保存的键值对内的键和值字符串长度小于一定值及键值对；
- Set
  - 保存元素为整数及元素个数小于一定范围使用 intset 编码，任意条件不满足，则使用 hashtable 编码；
- Zset
  - zset 对象中保存的元素个数小于及成员长度小于一定值使用 ziplist 编码，任意条件不满足，则使用 skiplist 编码。

### 合适的线程模型

- IO多路复用
  - IO：网络IO
  - 多路：多个TCP连接
  - 复用：公用一个线程或者进程，避免了进程切换

## 安装



- ```shell
  redis-cli -h 127.0.0.1 -p 6379 shutdown
  ```

- redis存放日志、数据、配置文件、可执行程序的默认位置

![image-20210317231731922](.\image\image-20210317231731922.png '位置')

## 启动Redis

- 命令：`redis-cli`,默认启动的是6379这个端口的服务，通过`redis-cli -p 端口号`，可以启动其他端口的服务

- redis默认可以有16个库，可以进入命令行后选择，也可以在进入命令行时选择`redis-cli -n`
  - ![image-20210320165011489](.\image\image-20210320165011489.png)
  - ![image-20210320165216875](.\image\image-20210320165216875.png)

## Redis使用

- 进入命令行之后，通过`help @xxx` 来得到某组的帮助
  - 比如：` help @generic` 查看全局的命令

##  类型

### String

- **缓存功能：String**字符串是最常用的数据类型，不仅仅是**Redis**，各个语言都是最基本类型，因此，利用**Redis**作为缓存，配合其它数据库作为存储层，利用**Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。
- **计数器：**许多系统都会使用**Redis**作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。
- **共享用户Session：**用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存**Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。

#### bitmap

#### List

- 比如可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。
- 内部是使用**双向链表**（double linked list）实现的，所以向列表两端添加元素的时间复杂度为0(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是极快的

- 比如可以通过 **lrange** 命令，读取某个闭区间内的元素，可以基于 **List** 实现分页查询，这个是很棒的一个功能，基于 **Redis** 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

  ````shell
  lrange list-key 0 -1
  1) "item"
  2) "item2"
  3) "item"
  ````

### sets集合

- 存储大量数据、查询速度快
- 数据不重复且没有顺序
- 内部使用散列表实现,所有这些操作的时间复杂度都为0(1)
- 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等，除此之外Redis还提供了多个集合之间的交集、并集、差集的运算。
- 直接基于 **Set** 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 **JVM** 内存里的 **HashSet** 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于**Redis**进行全局的 **Set** 去重。

### sorted sets有序集合

- 使用散列表实现

- 如果添加重复的数据，score会被最后一次的覆盖

- 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

- 用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

   微博热搜榜，就是有个后面的热度值，前面就是名称

   ````sh
   zadd key score1 value1 score2 value2..  --添加数据，向有序集合中加入一个元素和该元素的分数，如果该										  元素已经存在则会用新的分数替换原有的分数
   										返回值是新加入到集合中的元素个数，不包含之前已经存在的元素
   
   zrange key start stop [WITHSCORES]      获取数据按照元素分数从小到大的顺序返回索引从start到stop之间的所有元素（包含两端的元素），
   										如果WITHSCORES在末尾，则会把score也输出出来
   zrevrange key srart stop [WITHSCORES]	按照元素分数从大到小的顺序返回索引从start到stop之间的所有										 元素，如果WITHSCORES在末尾，则会把score也输出出来。
   zcard key 					 			获取数据总量
   zcount key min max 						获取[min, max]范围内的数据数量
   zrem key value 							删除数据
   
   
   > zadd zset-key 728 member1
   (integer) 1
   > zadd zset-key 982 member0
   (integer) 1
   > zadd zset-key 982 member0
   (integer) 0
   
   > zrange zset-key 0 -1 withscores
   1) "member1"
   2) "728"
   3) "member0"
   4) "982"
   
   > zrangebyscore zset-key 0 800 withscores
   1) "member1"
   2) "728"
   
   > zrem zset-key member1
   (integer) 1
   > zrem zset-key member1
   (integer) 0
   
   > zrange zset-key 0 -1 withscores
   1) "member0"
   2) "982"
   
   ````

   



## RDB、AOF

### RDB：快照副本（默认开启）

-  你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

- 在配置文件中配置RDB

  - ![image-20210601172514465.png](image\image-20210601172514465.png)

  - ````shell
     save 900 1
     save 300 10
     save 60 10000
    # 如果达到60s,但是操作还没有1000次，那么就进入save 300 10 ，如果没有达到300 10 ，就进入第一行
    ````

  - 如果想关闭RDB，那么就配置为 `save ""` ,或者这三个配置

  - 永远只有一个rdb文件，需要每天定时获取并且存储。

  - 如果父进程改变了数据，由于写时复制，会将修改的数据复制一份给bgsave访问

### AOF

- AOF默认是关闭的

- Redis的写操作记录到文件中

- 4.0以后，AOF包含RDB全量，增加新的写操作

- 先将老的数据将RDB到aof文件，将增量以指令的方式追加到aof

- 配置

  - 这是三种方式 

    - ````shell
      # appendfsync always  写一个命令就追加到磁盘（最可靠）
      # appendfsync everysec 每秒
      # appendfsync no 先将命令保存到buffer中，buffer满了在追加到磁盘，这个buffer可以调整大小
      
      ````

    - 

  - ![image-20210601185532405](.\image\image-20210601185532405.png)

- Rewrite ：AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件超过所设定的阈值，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewriteaof

  重写原理：AOF文件持续增长而过大时，会fork出一条新进程来讲文件重写（先写临时文件最后在rename）遍历新进程内存中的数据，每条数据记录中有一条set语句。重写aof文件的操作，并没有读取旧得aof文件，而是将整个内存中得数据库内容用命令得方式重写了一个aof文件，这点和快照有点相似

- redis5之后使用rdb和aof的方式，重写的时候先把rdb文件先重写，然后把aof文件追加到重写的文件中，速度较快

- 百分比100，是指redis会记录上次重写的aof文件的大小，当aof文件的大于等于上次重写文件大小的100%（可以改）同时重写时候文件的大小最少是64M（可以改），防止重写的aof文件偏小而频繁进行重写。

  听起来，aof比rdb更好点，实际上，在redis4之前使用的是aof。即使你开启rdb也不生效。

### 混合

- 在redis4.0之后是混合持久化机制，在4.0默认是关闭的，5.0之后默认是开启的。配置文件中通过aof-use-rdb-preamble参数控制，yes为开启no为关闭。混合持久化是通过bgrewriteaof完成的，不同的是当开启混合持久化时，folk出的子进程先将共享的内存副本全量以rdb方式写入aof文件，然后再将从写缓冲区增量命令以aof的方式写入文件，写入完成后通知主进程更新统计信息，并将新的含有rdb格式和aof格式的aof文件替换旧的aof文件。简单而言，新的aof文件前半段是rdb格式的全量数据，后半段是aof格式的增量数据。
  
  优点：混合持久化结合了rdb和aof的优势，由于绝大多数都是rdb二进制格式，因此加载快，同时结合aof保存增量数据使得数据丢失少；
  
  缺点：兼容性差，一旦开启混合持久化，那么4.0之前的版本都不能识别这个混合持久化文件，同时前半段包含rdb二进制格式会导致阅读性差。

## 缓存和数据库的区别

- 缓存的数据不重要

  1. 首先：缓存不是全量数据
  2. 第二：缓存应该随着访问变化，缓存里应该存放热数据
  3. redis如何随着访问变化？因为内存大小有限
     1. key要有有效期，有效期随着业务变化
     2. 随着访问变化，如何删除无效数据\
     3. ![image-20210404231534616](image\image-20210404231534616.png)


## 发布订阅

-  `publish oxx demo ` 会向oxx这个通道发送一个demo，通过`subsribe oxx` 能接收到demo，前提是，先订阅，然后再发布，否则，先发布之后，订阅是无法收取到消息的
- 

## redis事务

- redis是单进程的，多个命令也都是一个一个执行的，多个事务会按照队列来进入redis，如果两个事务开始后，事务2先发送了某个命令，事务1后发送了某个命令，那么就会先执行事务2，而不是事务1，决定到底是哪个事务先执行，是看哪个事务先执行了exec操作
  - `exec`：执行事务中所有在排队等待的指令并将链接状态恢复到正常 当使用[WATCH](http://www.redis.cn/commands/watch.html) 时，只有当被监视的键没有被修改，且允许检查设定机制时，EXEC会被执行。
- `watch`: 监控某个key，假设一个进程A进行监控某一个key，进行事务的时候，另一个进程B也开启了事务，B对key进行了删除或者更改值，当B提交的时候，A也提交了，那么A就会执行失败，出现`nil`，也就是说，当进行监控某一个key的时候，如果这个key被别的进程更改或者删除了，那么就会执行失败，这是CAS操作。

## 分布式锁

- 这是为了解决分布式集群中，对同一数据访问的并发问题，或者说控制多个集群在同一时间点，只有一个集群在访问这个数据。
- 例子：
  - 统计服务的定时任务，防止当前节点没有执行完，集群中的另一个节点就开始执行。

![分布式锁](.\image\分布式锁.png)



# Redis Sentinel 与 Redis Cluster

- https://blog.csdn.net/angjunqiang/article/details/81190562

## 回收策略

当maxmemory限制达到的时候Redis会使用的行为由 Redis的maxmemory-policy配置指令来进行配置。

以下的策略是可用的:

### **noeviction**

- 返回错误当内存限制达到

### **allkeys-lru**

- 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。

### **volatile-lru**

- 只从设置失效时间的key中选择最近最不经常使用的key进行删除，用以保存新数据(**如果主要是缓存数据，比较适合这个**)

### **allkeys-random**

- 回收随机的键使得新添加的数据有空间存放。

### **volatile-random**:

- 回收设置过期时间的随机的键使得新添加的数据有空间存放

### **volatile-ttl**: 

- 在设置了过期时间的所有键，抛弃存活时间最短的数据

### 建议

- 如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

- 选择正确的回收策略是非常重要的，这取决于你的应用的访问模式，不过你可以在运行时进行相关的策略调整，并且监控缓存命中率和没命中的次数，通过RedisINFO命令输出以便调优。

一般的经验规则:

- 使用**allkeys-lru**策略：当你希望你的请求符合一个幂定律分布，也就是说，你希望部分的子集元素将比其它其它元素被访问的更多。如果你不确定选择什么，这是个很好的选择。.
- 使用**allkeys-random**：如果你是循环访问，所有的键被连续的扫描，或者你希望请求分布正常（所有元素被访问的概率都差不多）。
- 使用**volatile-ttl**：如果你想要通过创建缓存对象时设置TTL值，来决定哪些对象应该被过期。

**allkeys-lru** 和 **volatile-random**策略对于当你想要单一的实例实现缓存及持久化一些键时很有用。不过一般运行两个实例是解决这个问题的更好方法。

为了键设置过期时间也是需要消耗内存的，所以使用**allkeys-lru**这种策略更加高效，因为没有必要为键取设置过期时间当内存有压力时。

## 缓存击穿

- 缓存击穿是指：缓存中没有数据或者缓存过期，直接去数据库查询，会造成数据压力过大。
- 解决办法
  1. 将缓存有效期改为永久，但写入缓存的地方就得是数据产生的地方

## 缓存雪崩

- 雪崩意味着redis挂掉或者大量key同时过期去查询数据库
  1. 如果大量的key同时去查询数据库，就将这些key设置一个随机的过期时间
  2. 如果时redis挂掉，那就保证集群的HA

## 缓存穿透

- 穿透是指：数据库中没数据、缓存中也没有
  1. 如果对于一个用户来讲，数据库中既有可能存在数据，也有可能不存在数据，那就将空值设置缓存
